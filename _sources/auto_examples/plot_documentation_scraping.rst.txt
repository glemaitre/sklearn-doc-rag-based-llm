
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_documentation_scraping.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_documentation_scraping.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_documentation_scraping.py:


=================================
Documentation scraping strategies
=================================

This example illustrates how the different documentation scraping strategies work
in `ragger_duck`.

.. GENERATED FROM PYTHON SOURCE LINES 11-22

API documentation scraping
--------------------------
First, we look at the :class:`~ragger_duck.scraping.APINumPyDocExtractor` class. This
class is used to scrape the API documentation of scikit-learn. It leverages the
`numpydoc` scraper and create semi-structured chunk of text.

Let's show an example where we scrape the documentation of
:class:`~sklearn.ensemble.RandomForestClassifier`. Our scrapper requires the HTML
generated file to infer if this is part of the public API. To do so,s we copied the
HTML generated file in the folder `toy_documentation/api`. We can therefore process
this folder.

.. GENERATED FROM PYTHON SOURCE LINES 22-29

.. code-block:: Python

    from pathlib import Path

    from ragger_duck.scraping import APINumPyDocExtractor

    path_api_doc = Path(".") / "toy_documentation" / "api"
    chunks = APINumPyDocExtractor().fit_transform(path_api_doc)








.. GENERATED FROM PYTHON SOURCE LINES 30-31

The chunks are stored in a list of dictionaries.

.. GENERATED FROM PYTHON SOURCE LINES 31-34

.. code-block:: Python

    print(f"Chunks is {type(chunks)}")
    print(f"A chunk is {type(chunks[0])}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Chunks is <class 'list'>
    A chunk is <class 'dict'>




.. GENERATED FROM PYTHON SOURCE LINES 35-37

A chunk contains 2 keys: `"source"` that is the HTML source page and `"text"` that is
the extracted text.

.. GENERATED FROM PYTHON SOURCE LINES 37-39

.. code-block:: Python

    chunks[0].keys()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    dict_keys(['source', 'text'])



.. GENERATED FROM PYTHON SOURCE LINES 40-42

For the API documentation, we use `numpydoc` to generate meaningful chunks. For
instance, this is the first chunk of text.

.. GENERATED FROM PYTHON SOURCE LINES 42-44

.. code-block:: Python

    print(chunks[0]["text"])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    sklearn.ensemble.RandomForestClassifier
    The parameters of RandomForestClassifier with their default values when known are: n_estimators (default=100), criterion (default=gini), max_depth (default=None), min_samples_split (default=2), min_samples_leaf (default=1), min_weight_fraction_leaf (default=0.0), max_features (default=sqrt), max_leaf_nodes (default=None), min_impurity_decrease (default=0.0), bootstrap (default=True), oob_score (default=False), n_jobs (default=None), random_state (default=None), verbose (default=0), warm_start (default=False), class_weight (default=None), ccp_alpha (default=0.0), max_samples (default=None), monotonic_cst (default=None).
    The description of the RandomForestClassifier is as follow.
    A random forest classifier.
    A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Trees in the forest use the best split strategy, i.e. equivalent to passing `splitter="best"` to the underlying :class:`~sklearn.tree.DecisionTreeRegressor`. The sub-sample size is controlled with the `max_samples` parameter if `bootstrap=True` (default), otherwise the whole dataset is used to build each tree.
    For a comparison between tree-based ensemble models see the example :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`.
    Read more in the :ref:`User Guide <forest>`.




.. GENERATED FROM PYTHON SOURCE LINES 45-56

The first line of the chunk corresponds to the estimator or class name and its
module. This information is useful to disambiguate the documentation when using an
LLM: sometimes we can have multiple parameters name defined in different classes or
functions. An LLM will tend to summarize the information coming from the different
chunks. However, if we provide the class or function name and this information is
present in the user prompt, then the LLM is likely to generate a more accurate
answer.

Since `numpydoc` offer a structured information based on the sections of the
docstring, we therefore use these sections and create hand-crafted chunks that we
find meaningful in regards to the API documentation.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.077 seconds)


.. _sphx_glr_download_auto_examples_plot_documentation_scraping.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_documentation_scraping.ipynb <plot_documentation_scraping.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_documentation_scraping.py <plot_documentation_scraping.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
