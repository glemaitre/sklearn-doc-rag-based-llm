
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_documentation_scraping.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_documentation_scraping.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_documentation_scraping.py:


=================================
Documentation scraping strategies
=================================

This example illustrates how the different documentation scraping strategies work
in `ragger_duck`.

.. GENERATED FROM PYTHON SOURCE LINES 11-22

API documentation scraping
--------------------------
First, we look at the :class:`~ragger_duck.scraping.APINumPyDocExtractor` class. This
class is used to scrape the API documentation of scikit-learn. It leverages the
`numpydoc` scraper and create semi-structured chunk of text.

Let's show an example where we scrape the documentation of
:class:`~sklearn.ensemble.RandomForestClassifier`. Our scrapper requires the HTML
generated file to infer if this is part of the public API. To do so,s we copied the
HTML generated file in the folder `toy_documentation/api`. We can therefore process
this folder.

.. GENERATED FROM PYTHON SOURCE LINES 22-29

.. code-block:: Python

    from pathlib import Path

    from ragger_duck.scraping import APINumPyDocExtractor

    path_api_doc = Path(".") / "toy_documentation" / "api"
    chunks = APINumPyDocExtractor().fit_transform(path_api_doc)








.. GENERATED FROM PYTHON SOURCE LINES 30-31

The chunks are stored in a list of dictionaries.

.. GENERATED FROM PYTHON SOURCE LINES 31-34

.. code-block:: Python

    print(f"Chunks is {type(chunks)}")
    print(f"A chunk is {type(chunks[0])}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Chunks is <class 'list'>
    A chunk is <class 'dict'>




.. GENERATED FROM PYTHON SOURCE LINES 35-37

A chunk contains 2 keys: `"source"` that is the HTML source page and `"text"` that is
the extracted text.

.. GENERATED FROM PYTHON SOURCE LINES 37-39

.. code-block:: Python

    chunks[0].keys()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    dict_keys(['source', 'text'])



.. GENERATED FROM PYTHON SOURCE LINES 40-42

For the API documentation, we use `numpydoc` to generate meaningful chunks. For
instance, this is the first chunk of text.

.. GENERATED FROM PYTHON SOURCE LINES 42-44

.. code-block:: Python

    print(chunks[0]["text"])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    sklearn.ensemble.RandomForestClassifier
    The parameters of RandomForestClassifier with their default values when known are: n_estimators (default=100), criterion (default=gini), max_depth (default=None), min_samples_split (default=2), min_samples_leaf (default=1), min_weight_fraction_leaf (default=0.0), max_features (default=sqrt), max_leaf_nodes (default=None), min_impurity_decrease (default=0.0), bootstrap (default=True), oob_score (default=False), n_jobs (default=None), random_state (default=None), verbose (default=0), warm_start (default=False), class_weight (default=None), ccp_alpha (default=0.0), max_samples (default=None), monotonic_cst (default=None).
    The description of the RandomForestClassifier is as follow.
    A random forest classifier.
    A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Trees in the forest use the best split strategy, i.e. equivalent to passing `splitter="best"` to the underlying :class:`~sklearn.tree.DecisionTreeRegressor`. The sub-sample size is controlled with the `max_samples` parameter if `bootstrap=True` (default), otherwise the whole dataset is used to build each tree.
    For a comparison between tree-based ensemble models see the example :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`.
    Read more in the :ref:`User Guide <forest>`.




.. GENERATED FROM PYTHON SOURCE LINES 45-64

The first line of the chunk corresponds to the estimator or class name and its
module. This information is useful to disambiguate the documentation when using an
LLM: sometimes we can have multiple parameters name defined in different classes or
functions. An LLM will tend to summarize the information coming from the different
chunks. However, if we provide the class or function name and this information is
present in the user prompt, then the LLM is likely to generate a more accurate
answer.

Since `numpydoc` offer a structured information based on the sections of the
docstring, we therefore use these sections and create hand-crafted chunks that we
find meaningful in regards to the API documentation.

User guide documentation scraping
---------------------------------
First, we look at the :class:`~ragger_duck.scraping.UserGuideExtractor` class. This
class is used to scrape the user guide documentation of scikit-learn. The chunking
strategy is really simple: we split the text into chunks of a fixed size.
Additionally, chunks can be overlapping. Those behaviors can be controlled by the
`chunk_size` and `chunk_overlap` parameters.

.. GENERATED FROM PYTHON SOURCE LINES 64-71

.. code-block:: Python

    from ragger_duck.scraping import UserGuideDocExtractor

    path_user_guide = Path(".") / "toy_documentation" / "user_guide"
    chunks = UserGuideDocExtractor(chunk_size=500, chunk_overlap=100).fit_transform(
        path_user_guide
    )








.. GENERATED FROM PYTHON SOURCE LINES 72-73

We provide an example of two overlapping chunks.

.. GENERATED FROM PYTHON SOURCE LINES 73-78

.. code-block:: Python

    print("Chunk #1\n")
    print(chunks[0]["text"])
    print("\nChunk #2\n")
    print(chunks[1]["text"])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Chunk #1

    Getting Started¶
    The purpose of this guide is to illustrate some of the main features that
    scikit-learn provides. It assumes a very basic working knowledge of
    machine learning practices (model fitting, predicting, cross-validation,
    etc.). Please refer to our installation instructions for installing scikit-learn.
    Scikit-learn is an open source machine learning library that supports
    supervised and unsupervised learning. It also provides various tools for

    Chunk #2

    supervised and unsupervised learning. It also provides various tools for
    model fitting, data preprocessing, model selection, model evaluation,
    and many other utilities.
    Fitting and predicting: estimator basics¶
    Scikit-learn provides dozens of built-in machine learning algorithms and
    models, called estimators. Each estimator can be fitted to some data
    using its fit method.
    Here is a simple example where we fit a
    RandomForestClassifier to some very basic data:




.. GENERATED FROM PYTHON SOURCE LINES 79-80

The size of the chunks might varies depending of the break characters in the text.

.. GENERATED FROM PYTHON SOURCE LINES 80-83

.. code-block:: Python

    print(len(chunks[0]["text"]))
    print(len(chunks[1]["text"]))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    456
    462




.. GENERATED FROM PYTHON SOURCE LINES 84-92

It should be noted that we could improve this strategy by using a more sophisticated
chunking strategy. For instance, we could detect the sections and make sure to not
define chunks overlapping between independent sections. In the same manner, we could
think of a strategy to not split code block of the user guide since they are quite
small and self-contained.

Examples documentation scraping
-------------------------------


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.106 seconds)


.. _sphx_glr_download_auto_examples_plot_documentation_scraping.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_documentation_scraping.ipynb <plot_documentation_scraping.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_documentation_scraping.py <plot_documentation_scraping.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
