[project]
name = "sklearn-ragger-duck"
version = "0.0.1.dev0"
description = "Ragger Duck is a RAG for the scikit-learn documentation."
authors = ["Guillaume Lemaitre <g.lemaite58@gmail.com>"]
channels = ["conda-forge", "pytorch"]
platforms = ["linux-64", "osx-64", "osx-arm64"]
license = "BSD-3-Clause"
homepage = "https://github.com/glemaitre/sklearn-ragger-duck"
readme = "README.md"

[tasks]
build-doc = { cmd = "make html", cwd = "doc" }
test = { cmd = "pytest -vsl --cov=ragger_duck --cov-report term-missing ragger_duck" }
fetch-mistral = { cmd = "wget -O 'mistral-7b-instruct-v0.2.Q6_K.gguf' 'https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q6_K.gguf?download=true'", cwd = "models" }

[dependencies]
python = "*"
# Dependencies for training retrievers and inference with models
beautifulsoup4 = "*"
joblib = "*"
langchain = "*"
numpydoc = "*"
# align the version of scikit-learn with the submodule one to avoid rebuilding it
scikit-learn = "1.4.1.post1"
sphinx-gallery = "*"
# Dependencies for the web app
fastapi = "*"
uvicorn = "*"
websockets = "*"
# Dependencies for the documentation
pydata-sphinx-theme = "*"
sphinx = "*"
# Dependencies for testing
pytest = "*"
pytest-cov = "*"

[system-requirements]
linux = "4.18"

# MPS-specfic configuration
[feature.mps]
platforms = ["osx-arm64"]

[feature.mps.activation]
# set environment variable for building llmama-cpp via pip
scripts = ["build_scripts/osx-arm64-activate.sh"]

[feature.mps.dependencies]
faiss-cpu = { version = "1.8.0", channel = "pytorch" }
libfaiss = { version = "1.8.0", channel = "pytorch" }
pytorch = { version = "2.2.1", channel = "pytorch" }
torchvision = { version = "*", channel = "pytorch" }
sentence-transformers = "2.6.0"

# [feature.mps.pypi-dependencies]
# the latest version requires xcode 15.2
# xcode 15.3 that is the latest release is buggy
# llama-cpp-python = "*"

# CPU-specfic configuration
[feature.cpu]
platforms = ["linux-64"]

[feature.cpu.activation]
# set environment variable for building llmama-cpp via pip
scripts = ["build_scripts/linux-64-cpu-activate.sh"]

[feature.cpu.dependencies]
faiss-cpu = { version = "1.8.0", channel = "pytorch" }
libfaiss = { version = "1.8.0", channel = "pytorch" }
pytorch = { version = "2.2.1", channel = "pytorch" }
cpuonly = { version = "*", channel = "pytorch" }
torchvision = { version = "*", channel = "pytorch" }
sentence-transformers = "2.6.0"

[feature.cpu.pypi-dependencies]
llama-cpp-python = "*"

# margaret-specfic configuration for CUDA 11.7
[feature.margaret]
platforms = ["linux-64"]
system-requirements = { cuda = "11.7" }
channels = ["nvidia", {channel = "pytorch", priority = -1}]

[feature.margaret.activation]
# set environment variable for building llmama-cpp via pip
scripts = ["build_scripts/margaret-activate.sh"]

[feature.margaret.dependencies]
faiss-cpu = { version = "1.8.0", channel = "pytorch" }
libfaiss = { version = "1.8.0", channel = "pytorch" }
cuda-nvcc = { version = "11.7.*", channel = "nvidia" }
cuda-toolkit = { version = "11.4.*", channel = "nvidia" }
cuda-runtime = { version = "11.7.*", channel = "nvidia" }
pytorch = { version = "2.0.1", channel = "pytorch" }
pytorch-cuda = { version = "11.7.*", channel = "pytorch" }
torchvision = { version = "*", channel = "pytorch" }
sentence-transformers = "2.6.0"

# [feature.margaret.pypi-dependencies]
# llama-cpp-python = "*"

# scaleway-specfic configuration for CUDA 12.4
[feature.scaleway]
platforms = ["linux-64"]
system-requirements = { cuda = "12.1" }
channels = ["nvidia", {channel = "pytorch", priority = -1}]

[feature.scaleway.activation]
# set environment variable for building llmama-cpp via pip
scripts = ["build_scripts/margaret-activate.sh"]

[feature.scaleway.dependencies]
faiss-cpu = { version = "1.8.0", channel = "pytorch" }
libfaiss = { version = "1.8.0", channel = "pytorch" }
cuda-nvcc = { version = "12.1.*", channel = "nvidia" }
cuda-toolkit = { version = "12.1.*", channel = "nvidia" }
cuda-runtime = { version = "12.1.*", channel = "nvidia" }
pytorch = { version = "2.2.1", channel = "pytorch" }
pytorch-cuda = { version = "12.1.*", channel = "pytorch" }
torchvision = { version = "*", channel = "pytorch" }
sentence-transformers = "2.6.0"

# [feature.scaleway.pypi-dependencies]
# llama-cpp-python = "*"

# tasks per type of hardware

[feature.cpu.tasks]
start-ragger-duck = { cmd = "DEVICE=cpu uvicorn main:app --reload --host 0.0.0.0 --port 8123", cwd = "app" }
train-retrievers = { cmd = "DEVICE=cpu python train_retrievers.py", cwd = "scripts" }

[feature.mps.tasks]
start-ragger-duck = { cmd = "DEVICE=mps GPU_LAYERS=-1 uvicorn main:app --reload --host 0.0.0.0 --port 8123", cwd = "app" }
train-retrievers = { cmd = "DEVICE=mps python train_retrievers.py", cwd = "scripts" }

[feature.cuda.tasks]
start-ragger-duck = { cmd = "DEVICE=cuda GPU_LAYERS=-1 uvicorn main:app --reload --host 0.0.0.0 --port 8123", cwd = "app" }
train-retrievers = { cmd = "DEVICE=cuda python train_retrievers.py", cwd = "scripts" }

[environments]
mps = ["mps"]
cpu = ["cpu"]
margaret = ["margaret", "cuda"]
scaleway = ["scaleway", "cuda"]
